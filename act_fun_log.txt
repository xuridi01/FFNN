Experiments with different activation functions on datasets MNIST and CIFAR-10
---MNIST---

Starting params:
-Epochs: 10
-Learning rate: 0.001
-Batch size: 64
-Optimizer: ADAM
-Loss function: CrossEntropy


RELU:

Epoch 1/10; Loss: 0.2799
Epoch 2/10; Loss: 0.1074
Epoch 3/10; Loss: 0.0707
Epoch 4/10; Loss: 0.0512
Epoch 5/10; Loss: 0.0379
Epoch 6/10; Loss: 0.0309
Epoch 7/10; Loss: 0.0236
Epoch 8/10; Loss: 0.0192
Epoch 9/10; Loss: 0.0165
Epoch 10/10; Loss: 0.0175
Correct: 9803/10000

SIGMOID:

Epoch 1/10; Loss: 0.5360
Epoch 2/10; Loss: 0.1842
Epoch 3/10; Loss: 0.1284
Epoch 4/10; Loss: 0.0962
Epoch 5/10; Loss: 0.0740
Epoch 6/10; Loss: 0.0582
Epoch 7/10; Loss: 0.0454
Epoch 8/10; Loss: 0.0366
Epoch 9/10; Loss: 0.0286
Epoch 10/10; Loss: 0.0229
Correct: 9785/10000

ELU:

Epoch 1/10; Loss: 0.2955
Epoch 2/10; Loss: 0.1317
Epoch 3/10; Loss: 0.0903
Epoch 4/10; Loss: 0.0662
Epoch 5/10; Loss: 0.0523
Epoch 6/10; Loss: 0.0428
Epoch 7/10; Loss: 0.0334
Epoch 8/10; Loss: 0.0279
Epoch 9/10; Loss: 0.0233
Epoch 10/10; Loss: 0.0209
Correct: 9756/10000

SELU:

Epoch 1/10; Loss: 0.2981
Epoch 2/10; Loss: 0.1461
Epoch 3/10; Loss: 0.1023
Epoch 4/10; Loss: 0.0787
Epoch 5/10; Loss: 0.0629
Epoch 6/10; Loss: 0.0528
Epoch 7/10; Loss: 0.0414
Epoch 8/10; Loss: 0.0362
Epoch 9/10; Loss: 0.0311
Epoch 10/10; Loss: 0.0258
Correct: 9764/10000

GELU:

Epoch 1/10; Loss: 0.2839
Epoch 2/10; Loss: 0.1096
Epoch 3/10; Loss: 0.0700
Epoch 4/10; Loss: 0.0508
Epoch 5/10; Loss: 0.0377
Epoch 6/10; Loss: 0.0300
Epoch 7/10; Loss: 0.0219
Epoch 8/10; Loss: 0.0178
Epoch 9/10; Loss: 0.0155
Epoch 10/10; Loss: 0.0135
Correct: 9739/10000

SILU:

Epoch 1/10; Loss: 0.2942
Epoch 2/10; Loss: 0.1161
Epoch 3/10; Loss: 0.0753
Epoch 4/10; Loss: 0.0530
Epoch 5/10; Loss: 0.0400
Epoch 6/10; Loss: 0.0300
Epoch 7/10; Loss: 0.0233
Epoch 8/10; Loss: 0.0187
Epoch 9/10; Loss: 0.0142
Epoch 10/10; Loss: 0.0109
Correct: 9824/10000



---CIFAR-10---

Starting params:
-Epochs: 10
-Learning rate: 0.005
-Batch size: 64
-Optimizer: ADAM
-Loss function: CrossEntropy


RELU:

Epoch 1/10; Loss: 2.0046
Epoch 2/10; Loss: 1.8444
Epoch 3/10; Loss: 1.8113
Epoch 4/10; Loss: 1.7935
Epoch 5/10; Loss: 1.7787
Epoch 6/10; Loss: 1.7708
Epoch 7/10; Loss: 1.7729
Epoch 8/10; Loss: 1.7681
Epoch 9/10; Loss: 1.7574
Epoch 10/10; Loss: 1.7577
Correct: 3637/10000

SIGMOID:

Epoch 1/10; Loss: 2.1475
Epoch 2/10; Loss: 2.1028
Epoch 3/10; Loss: 2.0984
Epoch 4/10; Loss: 2.0855
Epoch 5/10; Loss: 2.0837
Epoch 6/10; Loss: 2.0855
Epoch 7/10; Loss: 2.0840
Epoch 8/10; Loss: 2.0832
Epoch 9/10; Loss: 2.0782
Epoch 10/10; Loss: 2.0852
Correct: 1761/10000

ELU:

Epoch 1/10; Loss: 2.3239
Epoch 2/10; Loss: 1.9523
Epoch 3/10; Loss: 1.8988
Epoch 4/10; Loss: 1.8562
Epoch 5/10; Loss: 1.8046
Epoch 6/10; Loss: 1.8076
Epoch 7/10; Loss: 1.7834
Epoch 8/10; Loss: 1.7662
Epoch 9/10; Loss: 1.7514
Epoch 10/10; Loss: 1.7082
Correct: 3825/10000

SELU:

Epoch 1/10; Loss: 2.4784
Epoch 2/10; Loss: 2.0746
Epoch 3/10; Loss: 2.0164
Epoch 4/10; Loss: 1.9902
Epoch 5/10; Loss: 1.9755
Epoch 6/10; Loss: 1.9470
Epoch 7/10; Loss: 1.9226
Epoch 8/10; Loss: 1.8936
Epoch 9/10; Loss: 1.8752
Epoch 10/10; Loss: 1.8390
Correct: 3412/10000

GELU:

Epoch 1/10; Loss: 2.1281
Epoch 2/10; Loss: 1.7704
Epoch 3/10; Loss: 1.7114
Epoch 4/10; Loss: 1.6872
Epoch 5/10; Loss: 1.6610
Epoch 6/10; Loss: 1.6455
Epoch 7/10; Loss: 1.6206
Epoch 8/10; Loss: 1.6191
Epoch 9/10; Loss: 1.6140
Epoch 10/10; Loss: 1.6065
Correct: 4066/10000

SILU:

Epoch 1/10; Loss: 2.0974
Epoch 2/10; Loss: 1.7585
Epoch 3/10; Loss: 1.7120
Epoch 4/10; Loss: 1.6871
Epoch 5/10; Loss: 2.0868
Epoch 6/10; Loss: 2.0299
Epoch 7/10; Loss: 1.9619
Epoch 8/10; Loss: 1.7818
Epoch 9/10; Loss: 1.6853
Epoch 10/10; Loss: 1.6612
Correct: 3727/10000
